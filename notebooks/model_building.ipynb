{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52057293",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660bc01b",
   "metadata": {},
   "source": [
    "There are several top notch deep learning frameworks that would suffice for this task; but in this case we'll be using __Tensorflow__ from __Google__.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c778e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# Important constants.\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "CHANNELS = 3\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40947161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with the Tensorflow data pipeline.\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r\"C:\\Users\\ifunanyaScript\\Everything\\BrainTumour_DiagnosisApp\\data\\clean_dataset\",\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size = (BATCH_SIZE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d89776",
   "metadata": {},
   "source": [
    "The dataset is loaded as batches specified by the \"batch_size\" parameter. In this case, 3000 images batched into sizes of 8. Thus, 375 batches and that would be the length of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279a166d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270e172",
   "metadata": {},
   "source": [
    "When one wants to train a model with a particular dataset, the normal practice is to split said dataset into separate chunks; particularly a training chunk and a testing chunk. The purpose of splitting the data is for evaluation purposes after training the model.  \n",
    "Most times, ML folks use __scikit-learn's__ ___train_test_split___. In this case, we'll use the ___take___ and ___skip___ attributes of the dataset object which allows us to grab a portion of the dataset by batches.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e4c58",
   "metadata": {},
   "source": [
    "The training chunk is always a lot larger that the validation chunk and testing chunk, so that the model is trained on as much data as possible. We'll set aside for training, validation and testing; 80%, 10%, 10% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b990e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset should be 300 batches\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "print(f\"The training dataset should be {int(len(dataset)*train_size)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82fc0912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes first 300 batches of the dataset\n",
    "train_ds = dataset.take(300)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9407a975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remaining data after the training chunk.\n",
    "remnant = dataset.skip(300)\n",
    "len(remnant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86fcdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation dataset should be 37 batches\n"
     ]
    }
   ],
   "source": [
    "val_size = 0.1\n",
    "print(f\"The validation dataset should be {int(len(dataset)*val_size)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e1a191a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes the first 37 batch of the remaining data.\n",
    "val_ds = remnant.take(37)\n",
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0554578e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes all the data after the first 37 batches.\n",
    "test_ds = remnant.skip(37)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2476ba",
   "metadata": {},
   "source": [
    "All of these snippets can be wrapped in a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c696c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(dataset, train_split=0.8, validation_split=0.1, test_split=0.1, shuffle=True, buffer=1000):\n",
    "    \"\"\"\n",
    "    The purpose of this function is to split a dataset into the necessary chunks and return\n",
    "    said chunks accordingly.\n",
    "    \n",
    "    A dataset is passed as an argument and the partitions are made with the predefined split sizes.\n",
    "    One can also alter the split sizes by changing the values while calling the function.\n",
    "    \"\"\"\n",
    "    \n",
    "    number_of_batches = len(dataset)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer, seed=321)\n",
    "    \n",
    "    train_size = int(train_split*number_of_batches)\n",
    "    validation_size = int(validation_split*number_of_batches)\n",
    "    \n",
    "    train_ds = dataset.take(train_size)\n",
    "    val_ds = dataset.skip(train_size).take(validation_size)\n",
    "    test_ds = dataset.skip(train_size).skip(validation_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2e9aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset of 94 batches was chunked as follows: \n",
      "300 batches for the Training dataset, \n",
      "37 batches for the Validation dataset and, \n",
      "38 batches for the Testing dataset.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = chunking(dataset)\n",
    "print(f\"\"\"The dataset of 94 batches was chunked as follows: \n",
    "{len(train_ds)} batches for the Training dataset, \n",
    "{len(val_ds)} batches for the Validation dataset and, \n",
    "{len(test_ds)} batches for the Testing dataset.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "820eb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c975f9e",
   "metadata": {},
   "source": [
    "Caching is used to improve data retrieval performance by reducing the need to access underlying storage.  \n",
    "In short, the dataset is cached in memory. This reduces training time because there will be no need open files and read images during each epoch.. The next epochs will reuse the data cached by the cache transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf29b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers for data_augmentation, resizing and rescaling.\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomContrast(0.5),\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.3),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.4)\n",
    "])\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05392f",
   "metadata": {},
   "source": [
    "As always, feature engineering/extraction is an essential step to training a reliably accurate model. However, one might ask how do you extract features when training a CNN. Well, the convolution filters in CNN hovers through the entire image and extracts features from the image. This is actually a rather simple mathematical process if you consider it.   \n",
    "We'll stack several convolutional layers together to grab enough features as possible. Also reducing dimensionality is very important so as to keep the trainable parameters(weights) concise and reduce training time, hence, we use Maxpooling.  \n",
    "After the convolutional layers we'll add a fully connected dense layer containing an arbitrary number of neurons and a final output layer activated by a sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3d6c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\", ),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Initialises the model.\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34cc8721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (8, 256, 256, 3)          0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 155,937\n",
      "Trainable params: 155,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b91028",
   "metadata": {},
   "source": [
    "Yowza!!!<br> \n",
    "We have to train over 155,900 weights.<br>\n",
    "This will take a pretty long time using a CPU.<br>\n",
    "Patience is a virtue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea00e821",
   "metadata": {},
   "source": [
    "As we know, backward propagation is one of two fundamental steps in training an __NN__. We'll use Adam optimizer for backward propagation.<br>\n",
    "Since it is binary classification __i.e__, no tumour[0] or tumour[1], we'll use BinaryCrossentropy to calculate the loss of the model's prediction compared to the actual labels.<br>\n",
    "Then we can track our model's performance with an accuracy metric.\n",
    "\n",
    "\n",
    "__NB:__ Backward propagation is a method sort of differencial calculus where we calculate the gradient of the loss function with respect to the parameters(weights and biases). Then we update said weights and biases according to minimise the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d003e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8239b579",
   "metadata": {},
   "source": [
    "We train the model by fitting it to the training dataset and we validate its performance with the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "229f3590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 378s 1s/step - loss: 0.6890 - accuracy: 0.5333 - val_loss: 0.6500 - val_accuracy: 0.6858\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 278s 917ms/step - loss: 0.6613 - accuracy: 0.6221 - val_loss: 0.5806 - val_accuracy: 0.7095\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 8601s 29s/step - loss: 0.6270 - accuracy: 0.6608 - val_loss: 0.6043 - val_accuracy: 0.6791\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 229s 765ms/step - loss: 0.5901 - accuracy: 0.6921 - val_loss: 0.5196 - val_accuracy: 0.7399\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 227s 756ms/step - loss: 0.5961 - accuracy: 0.6933 - val_loss: 0.5210 - val_accuracy: 0.7601\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 228s 760ms/step - loss: 0.5673 - accuracy: 0.7183 - val_loss: 0.5007 - val_accuracy: 0.7635\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 226s 752ms/step - loss: 0.5454 - accuracy: 0.7312 - val_loss: 0.4856 - val_accuracy: 0.7703\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 228s 759ms/step - loss: 0.5379 - accuracy: 0.7454 - val_loss: 0.4949 - val_accuracy: 0.7466\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 225s 752ms/step - loss: 0.5111 - accuracy: 0.7667 - val_loss: 0.4490 - val_accuracy: 0.7939\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 227s 755ms/step - loss: 0.5024 - accuracy: 0.7604 - val_loss: 0.4383 - val_accuracy: 0.7939\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 225s 752ms/step - loss: 0.4935 - accuracy: 0.7713 - val_loss: 0.4134 - val_accuracy: 0.8243\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 225s 751ms/step - loss: 0.4759 - accuracy: 0.7812 - val_loss: 0.4359 - val_accuracy: 0.7939\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 227s 757ms/step - loss: 0.4476 - accuracy: 0.7996 - val_loss: 0.4082 - val_accuracy: 0.8277\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 225s 750ms/step - loss: 0.4345 - accuracy: 0.7987 - val_loss: 0.3264 - val_accuracy: 0.8480\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 226s 752ms/step - loss: 0.4304 - accuracy: 0.8121 - val_loss: 0.2859 - val_accuracy: 0.8885\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 226s 755ms/step - loss: 0.3892 - accuracy: 0.8342 - val_loss: 0.3326 - val_accuracy: 0.8547\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 226s 754ms/step - loss: 0.3973 - accuracy: 0.8358 - val_loss: 0.2790 - val_accuracy: 0.8953\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 226s 755ms/step - loss: 0.3546 - accuracy: 0.8425 - val_loss: 0.2700 - val_accuracy: 0.8649\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 230s 768ms/step - loss: 0.3309 - accuracy: 0.8633 - val_loss: 0.2631 - val_accuracy: 0.9020\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 233s 778ms/step - loss: 0.3299 - accuracy: 0.8612 - val_loss: 0.2662 - val_accuracy: 0.9054\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 1217s 4s/step - loss: 0.3219 - accuracy: 0.8675 - val_loss: 0.2925 - val_accuracy: 0.8919\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 288s 960ms/step - loss: 0.2896 - accuracy: 0.8867 - val_loss: 0.2708 - val_accuracy: 0.8851\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 233s 778ms/step - loss: 0.2744 - accuracy: 0.8833 - val_loss: 0.2335 - val_accuracy: 0.8919\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 230s 768ms/step - loss: 0.2656 - accuracy: 0.8929 - val_loss: 0.2103 - val_accuracy: 0.9054\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 229s 765ms/step - loss: 0.2430 - accuracy: 0.8975 - val_loss: 0.3136 - val_accuracy: 0.8784\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 229s 763ms/step - loss: 0.2589 - accuracy: 0.8983 - val_loss: 0.2259 - val_accuracy: 0.8953\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 241s 802ms/step - loss: 0.2333 - accuracy: 0.9071 - val_loss: 0.3050 - val_accuracy: 0.8818\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 231s 769ms/step - loss: 0.2406 - accuracy: 0.9087 - val_loss: 0.1979 - val_accuracy: 0.9257\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 231s 769ms/step - loss: 0.2281 - accuracy: 0.9029 - val_loss: 0.3357 - val_accuracy: 0.8953\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 232s 772ms/step - loss: 0.2184 - accuracy: 0.9196 - val_loss: 0.2173 - val_accuracy: 0.9088\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 231s 769ms/step - loss: 0.2207 - accuracy: 0.9212 - val_loss: 0.1726 - val_accuracy: 0.9257\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 231s 770ms/step - loss: 0.2170 - accuracy: 0.9142 - val_loss: 0.1692 - val_accuracy: 0.9324\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 231s 771ms/step - loss: 0.2197 - accuracy: 0.9146 - val_loss: 0.2232 - val_accuracy: 0.9122\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 231s 771ms/step - loss: 0.2004 - accuracy: 0.9217 - val_loss: 0.2005 - val_accuracy: 0.9324\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 230s 768ms/step - loss: 0.1881 - accuracy: 0.9300 - val_loss: 0.1167 - val_accuracy: 0.9527\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 231s 771ms/step - loss: 0.2038 - accuracy: 0.9175 - val_loss: 0.1107 - val_accuracy: 0.9662\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 232s 774ms/step - loss: 0.1938 - accuracy: 0.9217 - val_loss: 0.1664 - val_accuracy: 0.9324\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 232s 772ms/step - loss: 0.1863 - accuracy: 0.9267 - val_loss: 0.2162 - val_accuracy: 0.8986\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 231s 769ms/step - loss: 0.1701 - accuracy: 0.9337 - val_loss: 0.1806 - val_accuracy: 0.9223\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 231s 772ms/step - loss: 0.1841 - accuracy: 0.9262 - val_loss: 0.2142 - val_accuracy: 0.9189\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 233s 776ms/step - loss: 0.1758 - accuracy: 0.9321 - val_loss: 0.1009 - val_accuracy: 0.9696\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 230s 768ms/step - loss: 0.1629 - accuracy: 0.9354 - val_loss: 0.1232 - val_accuracy: 0.9595\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 259s 864ms/step - loss: 0.1606 - accuracy: 0.9375 - val_loss: 0.1522 - val_accuracy: 0.9324\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 231s 770ms/step - loss: 0.1812 - accuracy: 0.9267 - val_loss: 0.1153 - val_accuracy: 0.9527\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 231s 769ms/step - loss: 0.1827 - accuracy: 0.9329 - val_loss: 0.0937 - val_accuracy: 0.9595\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 232s 774ms/step - loss: 0.1582 - accuracy: 0.9358 - val_loss: 0.0997 - val_accuracy: 0.9595\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 231s 771ms/step - loss: 0.1610 - accuracy: 0.9425 - val_loss: 0.0842 - val_accuracy: 0.9662\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 232s 772ms/step - loss: 0.1517 - accuracy: 0.9388 - val_loss: 0.0562 - val_accuracy: 0.9831\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 232s 772ms/step - loss: 0.1349 - accuracy: 0.9479 - val_loss: 0.0908 - val_accuracy: 0.9628\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 232s 774ms/step - loss: 0.1636 - accuracy: 0.9354 - val_loss: 0.1232 - val_accuracy: 0.9426\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 232s 772ms/step - loss: 0.1526 - accuracy: 0.9438 - val_loss: 0.1194 - val_accuracy: 0.9595\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 232s 774ms/step - loss: 0.1494 - accuracy: 0.9442 - val_loss: 0.0979 - val_accuracy: 0.9595\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 230s 767ms/step - loss: 0.1324 - accuracy: 0.9588 - val_loss: 0.0887 - val_accuracy: 0.9696\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 230s 766ms/step - loss: 0.1422 - accuracy: 0.9446 - val_loss: 0.1049 - val_accuracy: 0.9662\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 232s 774ms/step - loss: 0.1357 - accuracy: 0.9500 - val_loss: 0.1322 - val_accuracy: 0.9628\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 235s 783ms/step - loss: 0.1485 - accuracy: 0.9483 - val_loss: 0.0980 - val_accuracy: 0.9595\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 231s 770ms/step - loss: 0.1651 - accuracy: 0.9350 - val_loss: 0.1231 - val_accuracy: 0.9595\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 232s 774ms/step - loss: 0.1340 - accuracy: 0.9488 - val_loss: 0.0944 - val_accuracy: 0.9662\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 231s 770ms/step - loss: 0.1357 - accuracy: 0.9496 - val_loss: 0.0914 - val_accuracy: 0.9662\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 231s 772ms/step - loss: 0.1324 - accuracy: 0.9533 - val_loss: 0.1411 - val_accuracy: 0.9493\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 231s 770ms/step - loss: 0.1321 - accuracy: 0.9508 - val_loss: 0.0866 - val_accuracy: 0.9730\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 231s 771ms/step - loss: 0.1369 - accuracy: 0.9475 - val_loss: 0.1261 - val_accuracy: 0.9595\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 232s 773ms/step - loss: 0.1349 - accuracy: 0.9450 - val_loss: 0.0854 - val_accuracy: 0.9764\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 232s 775ms/step - loss: 0.1370 - accuracy: 0.9550 - val_loss: 0.0910 - val_accuracy: 0.9696\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 230s 768ms/step - loss: 0.1306 - accuracy: 0.9558 - val_loss: 0.1135 - val_accuracy: 0.9595\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 255s 851ms/step - loss: 0.1249 - accuracy: 0.9542 - val_loss: 0.0684 - val_accuracy: 0.9831\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 286s 955ms/step - loss: 0.1292 - accuracy: 0.9554 - val_loss: 0.0836 - val_accuracy: 0.9696\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 300s 1s/step - loss: 0.1262 - accuracy: 0.9496 - val_loss: 0.0850 - val_accuracy: 0.9628\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 40655s 136s/step - loss: 0.1169 - accuracy: 0.9642 - val_loss: 0.0663 - val_accuracy: 0.9730\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 1035s 3s/step - loss: 0.1320 - accuracy: 0.9550 - val_loss: 0.0775 - val_accuracy: 0.9730\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 1251s 4s/step - loss: 0.1289 - accuracy: 0.9517 - val_loss: 0.1078 - val_accuracy: 0.9561\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 1049s 3s/step - loss: 0.1338 - accuracy: 0.9517 - val_loss: 0.0999 - val_accuracy: 0.9527\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 1026s 3s/step - loss: 0.1242 - accuracy: 0.9496 - val_loss: 0.0606 - val_accuracy: 0.9764\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 224s 746ms/step - loss: 0.1036 - accuracy: 0.9633 - val_loss: 0.0844 - val_accuracy: 0.9628\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 225s 750ms/step - loss: 0.1218 - accuracy: 0.9588 - val_loss: 0.0594 - val_accuracy: 0.9831\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 226s 755ms/step - loss: 0.0964 - accuracy: 0.9650 - val_loss: 0.1534 - val_accuracy: 0.9257\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 226s 754ms/step - loss: 0.1185 - accuracy: 0.9575 - val_loss: 0.0462 - val_accuracy: 0.9899\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 226s 752ms/step - loss: 0.1270 - accuracy: 0.9521 - val_loss: 0.0574 - val_accuracy: 0.9899\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 225s 752ms/step - loss: 0.1114 - accuracy: 0.9608 - val_loss: 0.1096 - val_accuracy: 0.9493\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 226s 754ms/step - loss: 0.1365 - accuracy: 0.9554 - val_loss: 0.0596 - val_accuracy: 0.9831\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 225s 749ms/step - loss: 0.1238 - accuracy: 0.9613 - val_loss: 0.0731 - val_accuracy: 0.9865\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 227s 758ms/step - loss: 0.0952 - accuracy: 0.9650 - val_loss: 0.0949 - val_accuracy: 0.9696\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 225s 751ms/step - loss: 0.1262 - accuracy: 0.9588 - val_loss: 0.0601 - val_accuracy: 0.9831\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 229s 764ms/step - loss: 0.0904 - accuracy: 0.9683 - val_loss: 0.0928 - val_accuracy: 0.9662\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 225s 751ms/step - loss: 0.0992 - accuracy: 0.9671 - val_loss: 0.0759 - val_accuracy: 0.9595\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 225s 751ms/step - loss: 0.1031 - accuracy: 0.9633 - val_loss: 0.0826 - val_accuracy: 0.9662\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 226s 753ms/step - loss: 0.1000 - accuracy: 0.9658 - val_loss: 0.0995 - val_accuracy: 0.9628\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 225s 751ms/step - loss: 0.1072 - accuracy: 0.9638 - val_loss: 0.0671 - val_accuracy: 0.9595\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 226s 755ms/step - loss: 0.0938 - accuracy: 0.9675 - val_loss: 0.0768 - val_accuracy: 0.9662\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 226s 754ms/step - loss: 0.1053 - accuracy: 0.9604 - val_loss: 0.1445 - val_accuracy: 0.9595\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 226s 753ms/step - loss: 0.1130 - accuracy: 0.9550 - val_loss: 0.0911 - val_accuracy: 0.9696\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 225s 751ms/step - loss: 0.1019 - accuracy: 0.9642 - val_loss: 0.0566 - val_accuracy: 0.9831\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 227s 755ms/step - loss: 0.1011 - accuracy: 0.9671 - val_loss: 0.0608 - val_accuracy: 0.9797\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 225s 751ms/step - loss: 0.0981 - accuracy: 0.9658 - val_loss: 0.0783 - val_accuracy: 0.9764\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 226s 755ms/step - loss: 0.0837 - accuracy: 0.9675 - val_loss: 0.0665 - val_accuracy: 0.9865\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 226s 754ms/step - loss: 0.1176 - accuracy: 0.9579 - val_loss: 0.0681 - val_accuracy: 0.9797\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 232s 773ms/step - loss: 0.1117 - accuracy: 0.9629 - val_loss: 0.1137 - val_accuracy: 0.9730\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 229s 765ms/step - loss: 0.0967 - accuracy: 0.9671 - val_loss: 0.0746 - val_accuracy: 0.9730\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 229s 763ms/step - loss: 0.0866 - accuracy: 0.9704 - val_loss: 0.0970 - val_accuracy: 0.9696\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 303s 1s/step - loss: 0.1104 - accuracy: 0.9596 - val_loss: 0.0479 - val_accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21be05",
   "metadata": {},
   "source": [
    "We'll carry out a final evaluation of the model to see its general performance.<br>\n",
    "We'll do this using the test dataset; a dataset it has not seen pri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "622c3c28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 79s 306ms/step - loss: 0.1036 - accuracy: 0.9572\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "112759d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "model.save(r\"C:\\Users\\ifunanyaScript\\Everything\\BrainTumour_DiagnosisApp\\models\\1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fa6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
