{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52057293",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660bc01b",
   "metadata": {},
   "source": [
    "There are several top notch deep learning frameworks that would suffice for this task; but in this case we'll be using __Tensorflow__ from __Google__.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c778e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# Important constants.\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "CHANNELS = 3\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40947161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with the Tensorflow data pipeline.\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    r\"C:\\Users\\ifunanyaScript\\Everything\\BrainTumour_DiagnosisApp\\data\\clean_dataset\",\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size = (BATCH_SIZE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d89776",
   "metadata": {},
   "source": [
    "The dataset is loaded as batches specified by the \"batch_size\" parameter. In this case, 3000 images batched into sizes of 8. Thus, 375 batches and that would be the length of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279a166d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270e172",
   "metadata": {},
   "source": [
    "When one wants to train a model with a particular dataset, the normal practice is to split said dataset into separate chunks; particularly a training chunk and a testing chunk. The purpose of splitting the data is for evaluation purposes after training the model.  \n",
    "Most times, ML folks use __scikit-learn's__ ___train_test_split___. In this case, we'll use the ___take___ and ___skip___ attributes of the dataset object which allows us to grab a portion of the dataset by batches.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e4c58",
   "metadata": {},
   "source": [
    "The training chunk is always a lot larger that the validation chunk and testing chunk, so that the model is trained on as much data as possible. We'll set aside for training, validation and testing; 80%, 10%, 10% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b990e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset should be 300 batches\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "print(f\"The training dataset should be {int(len(dataset)*train_size)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82fc0912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes first 300 batches of the dataset\n",
    "train_ds = dataset.take(300)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9407a975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remaining data after the training chunk.\n",
    "remnant = dataset.skip(300)\n",
    "len(remnant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86fcdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation dataset should be 37 batches\n"
     ]
    }
   ],
   "source": [
    "val_size = 0.1\n",
    "print(f\"The validation dataset should be {int(len(dataset)*val_size)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e1a191a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes the first 37 batch of the remaining data.\n",
    "val_ds = remnant.take(37)\n",
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0554578e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes all the data after the first 37 batches.\n",
    "test_ds = remnant.skip(37)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2476ba",
   "metadata": {},
   "source": [
    "All of these snippets can be wrapped in a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c696c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(dataset, train_split=0.8, validation_split=0.1, test_split=0.1, shuffle=True, buffer=1000):\n",
    "    \"\"\"\n",
    "    The purpose of this function is to split a dataset into the necessary chunks and return\n",
    "    said chunks accordingly.\n",
    "    \n",
    "    A dataset is passed as an argument and the partitions are made with the predefined split sizes.\n",
    "    One can also alter the split sizes by changing the values while calling the function.\n",
    "    \"\"\"\n",
    "    \n",
    "    number_of_batches = len(dataset)\n",
    "    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer, seed=321)\n",
    "    \n",
    "    train_size = int(train_split*number_of_batches)\n",
    "    validation_size = int(validation_split*number_of_batches)\n",
    "    \n",
    "    train_ds = dataset.take(train_size)\n",
    "    val_ds = dataset.skip(train_size).take(validation_size)\n",
    "    test_ds = dataset.skip(train_size).skip(validation_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2e9aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset of 94 batches was chunked as follows: \n",
      "300 batches for the Training dataset, \n",
      "37 batches for the Validation dataset and, \n",
      "38 batches for the Testing dataset.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = chunking(dataset)\n",
    "print(f\"\"\"The dataset of 94 batches was chunked as follows: \n",
    "{len(train_ds)} batches for the Training dataset, \n",
    "{len(val_ds)} batches for the Validation dataset and, \n",
    "{len(test_ds)} batches for the Testing dataset.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "820eb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c975f9e",
   "metadata": {},
   "source": [
    "Caching is used to improve data retrieval performance by reducing the need to access underlying storage.  \n",
    "In short, the dataset is cached in memory. This reduces training time because there will be no need open files and read images during each epoch.. The next epochs will reuse the data cached by the cache transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf29b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers for data_augmentation, resizing and rescaling.\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomContrast(0.5),\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.3),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.4)\n",
    "])\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3d6c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "# num_classes = 2\n",
    "\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(16, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34cc8721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (8, 256, 256, 3)          0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 256, 256, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      9280      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,953\n",
      "Trainable params: 173,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d003e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "229f3590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 1229s 4s/step - loss: 0.6937 - accuracy: 0.5233 - val_loss: 0.6953 - val_accuracy: 0.5405\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 1066s 4s/step - loss: 0.6597 - accuracy: 0.6054 - val_loss: 0.6204 - val_accuracy: 0.6115\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 1027s 3s/step - loss: 0.6494 - accuracy: 0.6254 - val_loss: 0.5814 - val_accuracy: 0.7466\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 1014s 3s/step - loss: 0.6032 - accuracy: 0.6796 - val_loss: 0.5271 - val_accuracy: 0.7905\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 504s 2s/step - loss: 0.5641 - accuracy: 0.7204 - val_loss: 0.5795 - val_accuracy: 0.6926\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 1009s 3s/step - loss: 0.5571 - accuracy: 0.7192 - val_loss: 0.5038 - val_accuracy: 0.8074\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 215s 718ms/step - loss: 0.5199 - accuracy: 0.7629 - val_loss: 0.3759 - val_accuracy: 0.8547\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 216s 719ms/step - loss: 0.4898 - accuracy: 0.7821 - val_loss: 0.3375 - val_accuracy: 0.8851\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 215s 718ms/step - loss: 0.4469 - accuracy: 0.8046 - val_loss: 0.3077 - val_accuracy: 0.8851\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 216s 720ms/step - loss: 0.4244 - accuracy: 0.8083 - val_loss: 0.3089 - val_accuracy: 0.8750\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 216s 718ms/step - loss: 0.3908 - accuracy: 0.8308 - val_loss: 0.2706 - val_accuracy: 0.9020\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 217s 724ms/step - loss: 0.4008 - accuracy: 0.8271 - val_loss: 0.2739 - val_accuracy: 0.8919\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 216s 719ms/step - loss: 0.3626 - accuracy: 0.8479 - val_loss: 0.3254 - val_accuracy: 0.8716\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 216s 720ms/step - loss: 0.3326 - accuracy: 0.8687 - val_loss: 0.2865 - val_accuracy: 0.8784\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 218s 726ms/step - loss: 0.3340 - accuracy: 0.8637 - val_loss: 0.2736 - val_accuracy: 0.9122\n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 217s 723ms/step - loss: 0.3166 - accuracy: 0.8625 - val_loss: 0.1936 - val_accuracy: 0.9358\n",
      "Epoch 17/50\n",
      "300/300 [==============================] - 216s 721ms/step - loss: 0.3059 - accuracy: 0.8729 - val_loss: 0.1674 - val_accuracy: 0.9324\n",
      "Epoch 18/50\n",
      "300/300 [==============================] - 218s 725ms/step - loss: 0.3073 - accuracy: 0.8763 - val_loss: 0.2274 - val_accuracy: 0.9054\n",
      "Epoch 19/50\n",
      "300/300 [==============================] - 217s 725ms/step - loss: 0.2890 - accuracy: 0.8813 - val_loss: 0.2087 - val_accuracy: 0.9189\n",
      "Epoch 20/50\n",
      "300/300 [==============================] - 218s 726ms/step - loss: 0.2706 - accuracy: 0.8867 - val_loss: 0.1922 - val_accuracy: 0.9358\n",
      "Epoch 21/50\n",
      "300/300 [==============================] - 216s 719ms/step - loss: 0.2648 - accuracy: 0.8958 - val_loss: 0.1775 - val_accuracy: 0.9392\n",
      "Epoch 22/50\n",
      "300/300 [==============================] - 216s 720ms/step - loss: 0.2552 - accuracy: 0.8921 - val_loss: 0.2432 - val_accuracy: 0.9020\n",
      "Epoch 23/50\n",
      "300/300 [==============================] - 8188s 27s/step - loss: 0.2511 - accuracy: 0.8975 - val_loss: 0.1802 - val_accuracy: 0.9459\n",
      "Epoch 24/50\n",
      "300/300 [==============================] - 218s 727ms/step - loss: 0.2355 - accuracy: 0.9129 - val_loss: 0.1733 - val_accuracy: 0.9358\n",
      "Epoch 25/50\n",
      "300/300 [==============================] - 216s 718ms/step - loss: 0.2417 - accuracy: 0.9046 - val_loss: 0.1992 - val_accuracy: 0.9291\n",
      "Epoch 26/50\n",
      "300/300 [==============================] - 214s 715ms/step - loss: 0.2405 - accuracy: 0.9038 - val_loss: 0.2033 - val_accuracy: 0.9257\n",
      "Epoch 27/50\n",
      "300/300 [==============================] - 215s 718ms/step - loss: 0.2299 - accuracy: 0.9071 - val_loss: 0.1725 - val_accuracy: 0.9358\n",
      "Epoch 28/50\n",
      "300/300 [==============================] - 215s 718ms/step - loss: 0.2030 - accuracy: 0.9158 - val_loss: 0.1913 - val_accuracy: 0.9189\n",
      "Epoch 29/50\n",
      "300/300 [==============================] - 216s 720ms/step - loss: 0.2101 - accuracy: 0.9283 - val_loss: 0.1641 - val_accuracy: 0.9527\n",
      "Epoch 30/50\n",
      "300/300 [==============================] - 216s 719ms/step - loss: 0.2248 - accuracy: 0.9142 - val_loss: 0.1623 - val_accuracy: 0.9426\n",
      "Epoch 31/50\n",
      "300/300 [==============================] - 219s 730ms/step - loss: 0.2195 - accuracy: 0.9137 - val_loss: 0.1097 - val_accuracy: 0.9561\n",
      "Epoch 32/50\n",
      "300/300 [==============================] - 216s 720ms/step - loss: 0.2067 - accuracy: 0.9254 - val_loss: 0.1335 - val_accuracy: 0.9459\n",
      "Epoch 33/50\n",
      "300/300 [==============================] - 215s 717ms/step - loss: 0.2030 - accuracy: 0.9175 - val_loss: 0.1222 - val_accuracy: 0.9527\n",
      "Epoch 34/50\n",
      "300/300 [==============================] - 216s 720ms/step - loss: 0.2142 - accuracy: 0.9208 - val_loss: 0.1446 - val_accuracy: 0.9358\n",
      "Epoch 35/50\n",
      "300/300 [==============================] - 217s 724ms/step - loss: 0.1976 - accuracy: 0.9192 - val_loss: 0.1305 - val_accuracy: 0.9561\n",
      "Epoch 36/50\n",
      "300/300 [==============================] - 216s 721ms/step - loss: 0.2078 - accuracy: 0.9200 - val_loss: 0.1483 - val_accuracy: 0.9527\n",
      "Epoch 37/50\n",
      "300/300 [==============================] - 217s 724ms/step - loss: 0.2008 - accuracy: 0.9208 - val_loss: 0.1178 - val_accuracy: 0.9527\n",
      "Epoch 38/50\n",
      "300/300 [==============================] - 217s 723ms/step - loss: 0.1873 - accuracy: 0.9304 - val_loss: 0.1626 - val_accuracy: 0.9392\n",
      "Epoch 39/50\n",
      "300/300 [==============================] - 217s 725ms/step - loss: 0.2074 - accuracy: 0.9183 - val_loss: 0.1862 - val_accuracy: 0.9426\n",
      "Epoch 40/50\n",
      "300/300 [==============================] - 217s 723ms/step - loss: 0.1912 - accuracy: 0.9258 - val_loss: 0.1408 - val_accuracy: 0.9493\n",
      "Epoch 41/50\n",
      "300/300 [==============================] - 218s 727ms/step - loss: 0.1750 - accuracy: 0.9333 - val_loss: 0.1162 - val_accuracy: 0.9527\n",
      "Epoch 42/50\n",
      "300/300 [==============================] - 218s 725ms/step - loss: 0.1841 - accuracy: 0.9308 - val_loss: 0.1384 - val_accuracy: 0.9561\n",
      "Epoch 43/50\n",
      "300/300 [==============================] - 218s 727ms/step - loss: 0.1867 - accuracy: 0.9342 - val_loss: 0.1288 - val_accuracy: 0.9561\n",
      "Epoch 44/50\n",
      "300/300 [==============================] - 217s 725ms/step - loss: 0.1975 - accuracy: 0.9229 - val_loss: 0.1390 - val_accuracy: 0.9459\n",
      "Epoch 45/50\n",
      "300/300 [==============================] - 216s 721ms/step - loss: 0.1761 - accuracy: 0.9296 - val_loss: 0.1248 - val_accuracy: 0.9493\n",
      "Epoch 46/50\n",
      "300/300 [==============================] - 215s 716ms/step - loss: 0.1511 - accuracy: 0.9408 - val_loss: 0.1060 - val_accuracy: 0.9628\n",
      "Epoch 47/50\n",
      "300/300 [==============================] - 215s 716ms/step - loss: 0.1604 - accuracy: 0.9388 - val_loss: 0.1299 - val_accuracy: 0.9459\n",
      "Epoch 48/50\n",
      "300/300 [==============================] - 218s 727ms/step - loss: 0.1885 - accuracy: 0.9312 - val_loss: 0.1194 - val_accuracy: 0.9662\n",
      "Epoch 49/50\n",
      "300/300 [==============================] - 214s 715ms/step - loss: 0.1746 - accuracy: 0.9346 - val_loss: 0.1158 - val_accuracy: 0.9628\n",
      "Epoch 50/50\n",
      "300/300 [==============================] - 217s 724ms/step - loss: 0.1708 - accuracy: 0.9371 - val_loss: 0.1368 - val_accuracy: 0.9493\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4d1bb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.callbacks.History"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabdc090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
